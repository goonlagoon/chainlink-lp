hadoop = sc._jvm.org.apache.hadoop
fs = hadoop.fs.FileSystem
conf = hadoop.conf.Configuration() 
path = hadoop.fs.Path('/user/raw')
for f in fs.get(conf).listStatus(path):
    print(f.getPath(), f.getLen())



URI           = sc._gateway.jvm.java.net.URI
Path          = sc._gateway.jvm.org.apache.hadoop.fs.Path
FileSystem    = sc._gateway.jvm.org.apache.hadoop.fs.FileSystem
Configuration = sc._gateway.jvm.org.apache.hadoop.conf.Configuration


fs = FileSystem.get(URI("hdfs://namenode:9000"), Configuration())

status = fs.listStatus(Path('/user/root/raw'))

for fileStatus in status:
    print(fileStatus.getPath())


path = "/user/root/raw"
fs = spark._jvm.org.apache.hadoop.fs.FileSystem.get(spark._jsc.hadoopConfiguration())
list_status = fs.listStatus(spark._jvm.org.apache.hadoop.fs.Path(path))
[file.getPath().getName() for file in list_status]

export SPARK_MASTER_URL=spark://${SPARK_MASTER_NAME}:${SPARK_MASTER_PORT}
PYSPARK_PYTHON=python3  /spark/bin/spark-submit \
    --master ${SPARK_MASTER_URL} \
    ${SPARK_SUBMIT_ARGS} \
    ${SPARK_APPLICATION_PYTHON_LOCATION} ${SPARK_APPLICATION_ARGS}

psql -U postgres -d liquidity
select * from lqdty_info;